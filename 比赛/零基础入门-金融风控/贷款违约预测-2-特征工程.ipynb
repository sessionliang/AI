{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(800000, 47)\n(200000, 46)\n"
    }
   ],
   "source": [
    "## 1. 导入数据\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/testA.csv')\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 特征值预处理\n",
    "\n",
    "### 2.1 缺失值处理\n",
    "\n",
    "首先查看缺失值特征值有哪些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['loanAmnt', 'term', 'interestRate', 'installment', 'employmentTitle', 'homeOwnership', 'annualIncome', 'verificationStatus', 'purpose', 'postCode', 'regionCode', 'dti', 'delinquency_2years', 'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'revolBal', 'revolUtil', 'totalAcc', 'initialListStatus', 'applicationType', 'title', 'policyCode', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14']\n['grade', 'subGrade', 'employmentLength', 'issueDate', 'earliesCreditLine']\n"
    }
   ],
   "source": [
    "# 区分出数值特征和对象特征\n",
    "numeric_features = list(train_data.select_dtypes(exclude='object').columns)\n",
    "object_features = list(filter(lambda x: x not in numeric_features, list(train_data.columns)))\n",
    "numeric_features.remove('id')\n",
    "numeric_features.remove('isDefault')\n",
    "print(numeric_features)\n",
    "print(object_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train_data 缺失值统计：\n\nid                        0\nloanAmnt                  0\nterm                      0\ninterestRate              0\ninstallment               0\ngrade                     0\nsubGrade                  0\nemploymentTitle           1\nemploymentLength      46799\nhomeOwnership             0\nannualIncome              0\nverificationStatus        0\nissueDate                 0\nisDefault                 0\npurpose                   0\npostCode                  1\nregionCode                0\ndti                     239\ndelinquency_2years        0\nficoRangeLow              0\nficoRangeHigh             0\nopenAcc                   0\npubRec                    0\npubRecBankruptcies      405\nrevolBal                  0\nrevolUtil               531\ntotalAcc                  0\ninitialListStatus         0\napplicationType           0\nearliesCreditLine         0\ntitle                     1\npolicyCode                0\nn0                    40270\nn1                    40270\nn2                    40270\nn3                    40270\nn4                    33239\nn5                    40270\nn6                    40270\nn7                    40270\nn8                    40271\nn9                    40270\nn10                   33239\nn11                   69752\nn12                   40270\nn13                   40270\nn14                   40270\ndtype: int64\ntest_data 缺失值统计：\n\nid                        0\nloanAmnt                  0\nterm                      0\ninterestRate              0\ninstallment               0\ngrade                     0\nsubGrade                  0\nemploymentTitle           0\nemploymentLength      11742\nhomeOwnership             0\nannualIncome              0\nverificationStatus        0\nissueDate                 0\npurpose                   0\npostCode                  0\nregionCode                0\ndti                      61\ndelinquency_2years        0\nficoRangeLow              0\nficoRangeHigh             0\nopenAcc                   0\npubRec                    0\npubRecBankruptcies      116\nrevolBal                  0\nrevolUtil               127\ntotalAcc                  0\ninitialListStatus         0\napplicationType           0\nearliesCreditLine         0\ntitle                     0\npolicyCode                0\nn0                    10111\nn1                    10111\nn2                    10111\nn3                    10111\nn4                     8394\nn5                    10111\nn6                    10111\nn7                    10111\nn8                    10111\nn9                    10111\nn10                    8394\nn11                   17575\nn12                   10111\nn13                   10111\nn14                   10111\ndtype: int64\n"
    }
   ],
   "source": [
    "print(\"train_data 缺失值统计：\\r\\n\")\n",
    "print(train_data.isnull().sum())\n",
    "print(\"test_data 缺失值统计：\\r\\n\")\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train_data employmentTitle is null: 0\ntrain_data postCode is null: 0\ntrain_data title is null: 0\n"
    }
   ],
   "source": [
    "# employmentTitle, postCode, title只有一条空数据，相对于80w来说，可以忽略不计。我们直接删除这三行数据即可。\n",
    "train_data = train_data.drop(index=(train_data.loc[train_data['employmentTitle'].isnull()].index))\n",
    "print(\"train_data employmentTitle is null:\", train_data['employmentTitle'].isnull().sum())\n",
    "train_data = train_data.drop(index=(train_data.loc[train_data['postCode'].isnull()].index))\n",
    "print(\"train_data postCode is null:\", train_data['postCode'].isnull().sum())\n",
    "train_data = train_data.drop(index=(train_data.loc[train_data['title'].isnull()].index))\n",
    "print(\"train_data title is null:\", train_data['title'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train_data 缺失值统计：\n\nid                        0\nloanAmnt                  0\nterm                      0\ninterestRate              0\ninstallment               0\ngrade                     0\nsubGrade                  0\nemploymentTitle           0\nemploymentLength      46799\nhomeOwnership             0\nannualIncome              0\nverificationStatus        0\nissueDate                 0\nisDefault                 0\npurpose                   0\npostCode                  0\nregionCode                0\ndti                       0\ndelinquency_2years        0\nficoRangeLow              0\nficoRangeHigh             0\nopenAcc                   0\npubRec                    0\npubRecBankruptcies        0\nrevolBal                  0\nrevolUtil                 0\ntotalAcc                  0\ninitialListStatus         0\napplicationType           0\nearliesCreditLine         0\ntitle                     0\npolicyCode                0\nn0                        0\nn1                        0\nn2                        0\nn3                        0\nn4                        0\nn5                        0\nn6                        0\nn7                        0\nn8                        0\nn9                        0\nn10                       0\nn11                       0\nn12                       0\nn13                       0\nn14                       0\ndtype: int64\ntest_data 缺失值统计：\n\nid                        0\nloanAmnt                  0\nterm                      0\ninterestRate              0\ninstallment               0\ngrade                     0\nsubGrade                  0\nemploymentTitle           0\nemploymentLength      11742\nhomeOwnership             0\nannualIncome              0\nverificationStatus        0\nissueDate                 0\npurpose                   0\npostCode                  0\nregionCode                0\ndti                       0\ndelinquency_2years        0\nficoRangeLow              0\nficoRangeHigh             0\nopenAcc                   0\npubRec                    0\npubRecBankruptcies        0\nrevolBal                  0\nrevolUtil                 0\ntotalAcc                  0\ninitialListStatus         0\napplicationType           0\nearliesCreditLine         0\ntitle                     0\npolicyCode                0\nn0                        0\nn1                        0\nn2                        0\nn3                        0\nn4                        0\nn5                        0\nn6                        0\nn7                        0\nn8                        0\nn9                        0\nn10                       0\nn11                       0\nn12                       0\nn13                       0\nn14                       0\ndtype: int64\n"
    }
   ],
   "source": [
    "# 数值类型填充中位数\n",
    "train_data[numeric_features] = train_data[numeric_features].fillna(train_data[numeric_features].median())\n",
    "test_data[numeric_features] = test_data[numeric_features].fillna(test_data[numeric_features].median())\n",
    "# 对象类型填充众数\n",
    "train_data[object_features] = train_data[object_features].fillna(train_data[object_features].mode())\n",
    "test_data[object_features] = test_data[object_features].fillna(test_data[object_features].mode())\n",
    "# 重新检查缺失值\n",
    "print(\"train_data 缺失值统计：\\r\\n\")\n",
    "print(train_data.isnull().sum())\n",
    "print(\"test_data 缺失值统计：\\r\\n\")\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 对象特征值转换为数值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 year        52489\n10+ years    262751\n2 years       72358\n3 years       64152\n4 years       47985\n5 years       50101\n6 years       37254\n7 years       35407\n8 years       36192\n9 years       30272\n< 1 year      64237\nNaN           46799\nName: employmentLength, dtype: int64\n1 year       13182\n10+ years    65772\n2 years      18207\n3 years      16011\n4 years      11833\n5 years      12543\n6 years       9328\n7 years       8823\n8 years       8976\n9 years       7594\n< 1 year     15989\nNaN          11742\nName: employmentLength, dtype: int64\n"
    }
   ],
   "source": [
    "# employmentLength 通过众数填充失败了，我们通过暂时保留Nan值，因为是分类属性，所以可以假设这个Nan是一个新的类型\n",
    "print(train_data['employmentLength'].value_counts(dropna=False).sort_index())\n",
    "print(test_data['employmentLength'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-1      46799\n 0      64237\n 1      52489\n 2      72358\n 3      64152\n 4      47985\n 5      50101\n 6      37254\n 7      35407\n 8      36192\n 9      30272\n 10    262751\nName: employmentLength, dtype: int64\n-1     11742\n 0     15989\n 1     13182\n 2     18207\n 3     16011\n 4     11833\n 5     12543\n 6      9328\n 7      8823\n 8      8976\n 9      7594\n 10    65772\nName: employmentLength, dtype: int64\n"
    }
   ],
   "source": [
    "# 处理employmentLength\n",
    "def employmentLengthToInt(data):\n",
    "    data['employmentLength'].replace(to_replace='10+ years', value='10 years', inplace=True)\n",
    "    data['employmentLength'].replace(to_replace='< 1 year', value='0 years', inplace=True)\n",
    "    data['employmentLength'].fillna('-1 years', inplace=True)\n",
    "    return data['employmentLength'].apply(lambda x: np.int8(str(x).split()[0]))\n",
    "train_data['employmentLength'] = employmentLengthToInt(train_data)\n",
    "test_data['employmentLength'] = employmentLengthToInt(test_data)\n",
    "\n",
    "# 检查结果\n",
    "print(train_data['employmentLength'].value_counts(dropna=False).sort_index())\n",
    "print(test_data['employmentLength'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['grade', 'subGrade', 'employmentLength', 'issueDate', 'earliesCreditLine']\n"
    }
   ],
   "source": [
    "print(object_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "B    233690\nC    227116\nA    139661\nD    119452\nE     55661\nF     19053\nG      5364\nName: grade, dtype: int64\n"
    }
   ],
   "source": [
    "# grade 可以自映射\n",
    "print(train_data['grade'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1    139661\n2    233690\n3    227116\n4    119452\n5     55661\n6     19053\n7      5364\nName: grade, dtype: int64\n1    34927\n2    58365\n3    56701\n4    29924\n5    14010\n6     4698\n7     1375\nName: grade, dtype: int64\n"
    }
   ],
   "source": [
    "grade_map = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7}\n",
    "train_data['grade'] = train_data['grade'].map(grade_map)\n",
    "test_data['grade'] = test_data['grade'].map(grade_map)\n",
    "\n",
    "# 检查结果\n",
    "print(train_data['grade'].value_counts(dropna=False).sort_index())\n",
    "print(test_data['grade'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C1    50763\nB4    49516\nB5    48965\nB3    48600\nC2    47068\nC3    44751\nC4    44271\nB2    44227\nB1    42382\nC5    40263\nA5    38045\nA4    30928\nD1    30538\nD2    26528\nA1    25909\nD3    23410\nA3    22655\nA2    22124\nD4    21138\nD5    17838\nE1    14064\nE2    12746\nE3    10925\nE4     9273\nE5     8653\nF1     5925\nF2     4340\nF3     3577\nF4     2859\nF5     2352\nG1     1759\nG2     1231\nG3      978\nG4      751\nG5      645\nName: subGrade, dtype: int64\n"
    }
   ],
   "source": [
    "# subGrade\n",
    "print(train_data['subGrade'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "11    25909\n12    22124\n13    22655\n14    30928\n15    38045\n21    42382\n22    44227\n23    48600\n24    49516\n25    48965\n31    50763\n32    47068\n33    44751\n34    44271\n35    40263\n41    30538\n42    26528\n43    23410\n44    21138\n45    17838\n51    14064\n52    12746\n53    10925\n54     9273\n55     8653\n61     5925\n62     4340\n63     3577\n64     2859\n65     2352\n71     1759\n72     1231\n73      978\n74      751\n75      645\nName: subGrade, dtype: int64\n11     6398\n12     5503\n13     5644\n14     7753\n15     9629\n21    10544\n22    10898\n23    12100\n24    12423\n25    12400\n31    12857\n32    11791\n33    11018\n34    11110\n35     9925\n41     7667\n42     6713\n43     5821\n44     5236\n45     4487\n51     3527\n52     3175\n53     2780\n54     2414\n55     2114\n61     1462\n62     1073\n63      906\n64      714\n65      543\n71      488\n72      325\n73      232\n74      166\n75      164\nName: subGrade, dtype: int64\n"
    }
   ],
   "source": [
    "# subGrade进行一下替换，子级别和级别\n",
    "def subGradeReplace(data):\n",
    "    data['subGrade'] = data['subGrade'].str[:1].apply(lambda x: str(grade_map[x])) + data['subGrade'].str[1:]\n",
    "    data['subGrade'] = data['subGrade'].astype('int8')\n",
    "    return data\n",
    "\n",
    "train_data = subGradeReplace(train_data)\n",
    "test_data = subGradeReplace(test_data)\n",
    "\n",
    "# 检查结果\n",
    "print(train_data['subGrade'].value_counts(dropna=False).sort_index())\n",
    "print(test_data['subGrade'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2007-06-01        1\n2007-07-01       21\n2007-08-01       23\n2007-09-01        7\n2007-10-01       26\n2007-11-01       24\n2007-12-01       55\n2008-01-01       91\n2008-02-01      105\n2008-03-01      130\n2008-04-01       92\n2008-05-01       38\n2008-06-01       33\n2008-07-01       52\n2008-08-01       38\n2008-09-01       19\n2008-10-01       62\n2008-11-01      113\n2008-12-01      134\n2009-01-01      145\n2009-02-01      160\n2009-03-01      162\n2009-04-01      166\n2009-05-01      190\n2009-06-01      191\n2009-07-01      223\n2009-08-01      231\n2009-09-01      270\n2009-10-01      305\n2009-11-01      376\n              ...  \n2016-07-01    12835\n2016-08-01    13301\n2016-09-01    10165\n2016-10-01    11243\n2016-11-01    11172\n2016-12-01    11562\n2017-01-01     9757\n2017-02-01     8057\n2017-03-01    10068\n2017-04-01     7746\n2017-05-01     9620\n2017-06-01     9005\n2017-07-01     8861\n2017-08-01     9172\n2017-09-01     8100\n2017-10-01     7129\n2017-11-01     7306\n2017-12-01     5915\n2018-01-01     5176\n2018-02-01     3995\n2018-03-01     4228\n2018-04-01     4160\n2018-05-01     3933\n2018-06-01     2878\n2018-07-01     2550\n2018-08-01     2108\n2018-09-01     1427\n2018-10-01     1252\n2018-11-01      962\n2018-12-01      746\nName: issueDate, Length: 139, dtype: int64\n2007-07-01       4\n2007-08-01       4\n2007-09-01       4\n2007-10-01       6\n2007-11-01       4\n2007-12-01      12\n2008-01-01      40\n2008-02-01      23\n2008-03-01      38\n2008-04-01      22\n2008-05-01       9\n2008-06-01      14\n2008-07-01      11\n2008-08-01      12\n2008-09-01       5\n2008-10-01      11\n2008-11-01      17\n2008-12-01      30\n2009-01-01      39\n2009-02-01      29\n2009-03-01      48\n2009-04-01      40\n2009-05-01      57\n2009-06-01      65\n2009-07-01      65\n2009-08-01      78\n2009-09-01      60\n2009-10-01     109\n2009-11-01      79\n2009-12-01      78\n              ... \n2016-07-01    3271\n2016-08-01    3260\n2016-09-01    2514\n2016-10-01    2838\n2016-11-01    2835\n2016-12-01    2887\n2017-01-01    2392\n2017-02-01    1972\n2017-03-01    2503\n2017-04-01    1922\n2017-05-01    2452\n2017-06-01    2307\n2017-07-01    2234\n2017-08-01    2287\n2017-09-01    1960\n2017-10-01    1765\n2017-11-01    1737\n2017-12-01    1529\n2018-01-01    1300\n2018-02-01    1057\n2018-03-01    1099\n2018-04-01    1033\n2018-05-01    1009\n2018-06-01     713\n2018-07-01     626\n2018-08-01     561\n2018-09-01     360\n2018-10-01     317\n2018-11-01     239\n2018-12-01     154\nName: issueDate, Length: 138, dtype: int64\n2342        1\n2372       21\n2403       23\n2434        7\n2464       26\n2495       24\n2525       55\n2556       91\n2587      105\n2616      130\n2647       92\n2677       38\n2708       33\n2738       52\n2769       38\n2800       19\n2830       62\n2861      113\n2891      134\n2922      145\n2953      160\n2981      162\n3012      166\n3042      190\n3073      191\n3103      223\n3134      231\n3165      270\n3195      305\n3226      376\n        ...  \n5660    12835\n5691    13301\n5722    10165\n5752    11243\n5783    11172\n5813    11562\n5844     9757\n5875     8057\n5903    10068\n5934     7746\n5964     9620\n5995     9005\n6025     8861\n6056     9172\n6087     8100\n6117     7129\n6148     7306\n6178     5915\n6209     5176\n6240     3995\n6268     4228\n6299     4160\n6329     3933\n6360     2878\n6390     2550\n6421     2108\n6452     1427\n6482     1252\n6513      962\n6543      746\nName: issueDateDt, Length: 139, dtype: int64\n2372       4\n2403       4\n2434       4\n2464       6\n2495       4\n2525      12\n2556      40\n2587      23\n2616      38\n2647      22\n2677       9\n2708      14\n2738      11\n2769      12\n2800       5\n2830      11\n2861      17\n2891      30\n2922      39\n2953      29\n2981      48\n3012      40\n3042      57\n3073      65\n3103      65\n3134      78\n3165      60\n3195     109\n3226      79\n3256      78\n        ... \n5660    3271\n5691    3260\n5722    2514\n5752    2838\n5783    2835\n5813    2887\n5844    2392\n5875    1972\n5903    2503\n5934    1922\n5964    2452\n5995    2307\n6025    2234\n6056    2287\n6087    1960\n6117    1765\n6148    1737\n6178    1529\n6209    1300\n6240    1057\n6268    1099\n6299    1033\n6329    1009\n6360     713\n6390     626\n6421     561\n6452     360\n6482     317\n6513     239\n6543     154\nName: issueDateDt, Length: 138, dtype: int64\n"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# issueDate 贷款发放的月份\n",
    "def createDayFeature(data, feature, new_feature, date):\n",
    "    data[feature] = pd.to_datetime(data[feature], format='%Y-%m-%d')\n",
    "    start_date = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "    data[new_feature] = data[feature].apply(lambda x: x-start_date).dt.days\n",
    "    return data\n",
    "\n",
    "# 添加一个天数日期\n",
    "train_data = createDayFeature(train_data, 'issueDate', 'issueDateDt', '2001-01-01')\n",
    "test_data = createDayFeature(test_data, 'issueDate', 'issueDateDt', '2001-01-01')\n",
    "\n",
    "# 检查结果\n",
    "print(train_data['issueDate'].value_counts(dropna=False).sort_index())\n",
    "print(test_data['issueDate'].value_counts(dropna=False).sort_index())\n",
    "print(train_data['issueDateDt'].value_counts(dropna=False).sort_index())\n",
    "print(test_data['issueDateDt'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Apr-1955       2\nApr-1958       1\nApr-1960       2\nApr-1961       4\nApr-1962       4\nApr-1963      12\nApr-1964      18\nApr-1965      21\nApr-1966      28\nApr-1967      29\nApr-1968      37\nApr-1969      46\nApr-1970      51\nApr-1971      57\nApr-1972      80\nApr-1973      98\nApr-1974     109\nApr-1975     130\nApr-1976     150\nApr-1977     183\nApr-1978     244\nApr-1979     263\nApr-1980     224\nApr-1981     277\nApr-1982     393\nApr-1983     485\nApr-1984     632\nApr-1985     664\nApr-1986     800\nApr-1987     827\n            ... \nSep-1986     887\nSep-1987     936\nSep-1988    1007\nSep-1989    1074\nSep-1990    1347\nSep-1991    1263\nSep-1992    1499\nSep-1993    2086\nSep-1994    2673\nSep-1995    3217\nSep-1996    3061\nSep-1997    3365\nSep-1998    4064\nSep-1999    4441\nSep-2000    4780\nSep-2001    4787\nSep-2002    5170\nSep-2003    5403\nSep-2004    5219\nSep-2005    4608\nSep-2006    3646\nSep-2007    2656\nSep-2008    1733\nSep-2009    1295\nSep-2010    1347\nSep-2011    1008\nSep-2012     575\nSep-2013     278\nSep-2014     104\nSep-2015       3\nName: earliesCreditLine, Length: 720, dtype: int64\n"
    }
   ],
   "source": [
    "# earliesCreditLine\n",
    "print(train_data['earliesCreditLine'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0         2001\n1         2002\n2         2006\n3         1999\n4         1977\n5         1998\n6         2006\n7         1994\n8         1994\n9         1993\n10        1996\n11        2007\n12        2014\n13        1983\n14        2011\n15        1996\n16        2002\n17        1995\n18        2001\n19        1999\n20        2004\n21        1995\n22        1976\n23        2000\n24        1999\n25        1995\n26        1996\n27        2008\n28        2000\n29        2000\n          ... \n799970    1998\n799971    1979\n799972    1984\n799973    2002\n799974    1964\n799975    1993\n799976    2003\n799977    2002\n799978    1992\n799979    1990\n799980    2001\n799981    1992\n799982    1996\n799983    2004\n799984    1998\n799985    1996\n799986    2005\n799987    2008\n799988    2004\n799989    2006\n799990    2002\n799991    2007\n799992    2001\n799993    2001\n799994    2007\n799995    2011\n799996    1989\n799997    2002\n799998    1994\n799999    2002\nName: earliesCreditLine, Length: 799997, dtype: int64\n0         1974\n1         2001\n2         2006\n3         2002\n4         2000\n5         2000\n6         1998\n7         2007\n8         2004\n9         1992\n10        2007\n11        2003\n12        2000\n13        1998\n14        1987\n15        1983\n16        2006\n17        2002\n18        1986\n19        2005\n20        1977\n21        2006\n22        2004\n23        2002\n24        2005\n25        1991\n26        1987\n27        1990\n28        2006\n29        1997\n          ... \n199970    2003\n199971    1992\n199972    1999\n199973    1999\n199974    1995\n199975    1999\n199976    2005\n199977    1996\n199978    2003\n199979    2007\n199980    2000\n199981    2008\n199982    1992\n199983    2001\n199984    1984\n199985    2003\n199986    2006\n199987    1999\n199988    2006\n199989    1988\n199990    1989\n199991    1991\n199992    1996\n199993    2007\n199994    2000\n199995    2005\n199996    2006\n199997    2001\n199998    2005\n199999    2002\nName: earliesCreditLine, Length: 200000, dtype: int64\n1944        1\n1946        2\n1950        5\n1951        7\n1952        6\n1953        5\n1954        5\n1955        9\n1956       11\n1957       15\n1958       24\n1959       40\n1960       58\n1961       53\n1962       83\n1963      117\n1964      170\n1965      234\n1966      238\n1967      382\n1968      431\n1969      582\n1970      588\n1971      643\n1972      964\n1973     1129\n1974     1226\n1975     1427\n1976     1820\n1977     2393\n        ...  \n1986     9205\n1987    10591\n1988    11813\n1989    14163\n1990    15549\n1991    14687\n1992    15891\n1993    22395\n1994    27332\n1995    30501\n1996    32465\n1997    33090\n1998    38850\n1999    45917\n2000    50624\n2001    53194\n2002    51060\n2003    50648\n2004    49280\n2005    44046\n2006    37924\n2007    28464\n2008    18252\n2009    11414\n2010    10613\n2011     9792\n2012     6628\n2013     3525\n2014     1475\n2015      201\nName: earliesCreditLine, Length: 68, dtype: int64\n1944        1\n1945        1\n1949        1\n1950        2\n1951        2\n1952        1\n1953        1\n1954        1\n1955        1\n1956        1\n1957        3\n1958        3\n1959       12\n1960        9\n1961       14\n1962       17\n1963       30\n1964       45\n1965       67\n1966       69\n1967       88\n1968      102\n1969      135\n1970      155\n1971      153\n1972      243\n1973      252\n1974      284\n1975      353\n1976      484\n        ...  \n1986     2210\n1987     2625\n1988     2908\n1989     3564\n1990     3964\n1991     3648\n1992     3933\n1993     5486\n1994     6786\n1995     7627\n1996     8187\n1997     8449\n1998     9694\n1999    11525\n2000    12581\n2001    13171\n2002    12833\n2003    12604\n2004    12482\n2005    10991\n2006     9481\n2007     7028\n2008     4445\n2009     2920\n2010     2716\n2011     2490\n2012     1676\n2013      850\n2014      388\n2015       50\nName: earliesCreditLine, Length: 69, dtype: int64\n"
    }
   ],
   "source": [
    "# earliesCreditLine 变成年即可\n",
    "def getYear(data, col):\n",
    "    print(data[col].apply(lambda x: int(x.strip()[-4:])))\n",
    "    data[col] = data[col].apply(lambda x: int(x.strip()[-4:]))\n",
    "    return data\n",
    "\n",
    "train_data = getYear(train_data, 'earliesCreditLine')\n",
    "test_data = getYear(test_data, 'earliesCreditLine')\n",
    "\n",
    "# 检查结果\n",
    "print(train_data['earliesCreditLine'].value_counts(dropna=False).sort_index())\n",
    "print(test_data['earliesCreditLine'].value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    395729\n1    317660\n2     86309\n3       185\n5        81\n4        33\nName: homeOwnership, dtype: int64\n"
    }
   ],
   "source": [
    "# homeOwnership\n",
    "print(train_data['homeOwnership'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1    309809\n2    248968\n0    241220\nName: verificationStatus, dtype: int64\n"
    }
   ],
   "source": [
    "# verificationStatus\n",
    "print(train_data['verificationStatus'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0     464094\n4     175432\n2      52129\n5      46276\n3      17579\n9       9238\n1       9106\n8       8657\n10      5652\n7       5373\n6       4354\n12      1363\n11       554\n13       190\nName: purpose, dtype: int64\n"
    }
   ],
   "source": [
    "# purpose\n",
    "print(train_data['purpose'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8     116921\n14     65767\n13     65041\n21     56671\n2      30513\n30     28634\n0      27180\n19     26197\n3      25766\n9      22902\n7      22600\n23     20919\n10     19604\n12     18543\n26     18432\n22     17722\n18     17286\n4      14176\n11     12929\n24     12776\n32     12065\n38     11982\n36     11644\n27     10521\n17      9863\n35      9669\n5       9581\n20      9124\n43      7701\n42      7267\n15      6690\n37      5998\n45      5932\n16      4325\n28      4036\n44      3963\n33      3817\n6       3496\n39      2943\n40      2287\n31      2261\n34      2136\n25      2102\n48      1880\n41      1778\n1       1624\n29      1560\n47      1213\n49      1001\n46       953\n50         6\nName: regionCode, dtype: int64\n"
    }
   ],
   "source": [
    "# regionCode\n",
    "print(train_data['regionCode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    784583\n1     15414\nName: applicationType, dtype: int64\n"
    }
   ],
   "source": [
    "# applicationType\n",
    "print(train_data['applicationType'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    466437\n1    333560\nName: initialListStatus, dtype: int64\n"
    }
   ],
   "source": [
    "# initialListStatus\n",
    "print(train_data['initialListStatus'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0    799997\nName: policyCode, dtype: int64\n1.0    200000\nName: policyCode, dtype: int64\n"
    }
   ],
   "source": [
    "# policyCode\n",
    "print(train_data['policyCode'].value_counts())\n",
    "print(test_data['policyCode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Index(['id', 'loanAmnt', 'term', 'interestRate', 'installment', 'grade',\n       'subGrade', 'employmentTitle', 'employmentLength', 'annualIncome',\n       ...\n       'regionCode_41', 'regionCode_42', 'regionCode_43', 'regionCode_44',\n       'regionCode_45', 'regionCode_46', 'regionCode_47', 'regionCode_48',\n       'regionCode_49', 'regionCode_50'],\n      dtype='object', length=114)\nIndex(['id', 'loanAmnt', 'term', 'interestRate', 'installment', 'grade',\n       'subGrade', 'employmentTitle', 'employmentLength', 'annualIncome',\n       ...\n       'regionCode_41', 'regionCode_42', 'regionCode_43', 'regionCode_44',\n       'regionCode_45', 'regionCode_46', 'regionCode_47', 'regionCode_48',\n       'regionCode_49', 'regionCode_50'],\n      dtype='object', length=113)\n"
    }
   ],
   "source": [
    "# 对分类变量做虚拟变量\n",
    "train_data = pd.get_dummies(train_data, columns=['homeOwnership', 'verificationStatus', 'purpose', 'regionCode'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['homeOwnership', 'verificationStatus', 'purpose', 'regionCode'], drop_first=True)\n",
    "\n",
    "print(train_data.columns)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除id, policyCode\n",
    "train_data.drop('id', axis=1, inplace=True)\n",
    "train_data.drop('policyCode', axis=1, inplace=True)\n",
    "test_data.drop('id', axis=1, inplace=True)\n",
    "test_data.drop('policyCode', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 异常值处理\n",
    "\n",
    "数据中检测异常值，是比较好检测的。需不需要处理异常值，是个比较复杂的问题。可以想象一下，这个异常值是因为失误录入的，还是认为写入的。通常如果是因为失误造成的异常值，那么异常值的分布应该比较均衡，这部分异常值就需要处理。如果是人为主动制造的异常值，通常对结果有很大影响，这类异常值应该保留。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "正常值    799997\nName: loanAmnt_outliers, dtype: int64\nloanAmnt_outliers\n正常值    159610\nName: isDefault, dtype: int64\n**********\n正常值    799997\nName: term_outliers, dtype: int64\nterm_outliers\n正常值    159610\nName: isDefault, dtype: int64\n**********\n正常值    794256\n异常值      5741\nName: interestRate_outliers, dtype: int64\ninterestRate_outliers\n异常值      2916\n正常值    156694\nName: isDefault, dtype: int64\n**********\n正常值    792043\n异常值      7954\nName: installment_outliers, dtype: int64\ninstallment_outliers\n异常值      2152\n正常值    157458\nName: isDefault, dtype: int64\n**********\n正常值    799997\nName: employmentTitle_outliers, dtype: int64\nemploymentTitle_outliers\n正常值    159610\nName: isDefault, dtype: int64\n**********\n正常值    793970\n异常值      6027\nName: annualIncome_outliers, dtype: int64\nannualIncome_outliers\n异常值       756\n正常值    158854\nName: isDefault, dtype: int64\n**********\n正常值    798928\n异常值      1069\nName: postCode_outliers, dtype: int64\npostCode_outliers\n异常值       221\n正常值    159389\nName: isDefault, dtype: int64\n**********\n正常值    798437\n异常值      1560\nName: dti_outliers, dtype: int64\ndti_outliers\n异常值       466\n正常值    159144\nName: isDefault, dtype: int64\n**********\n正常值    788258\n异常值     11739\nName: ficoRangeLow_outliers, dtype: int64\nficoRangeLow_outliers\n异常值       778\n正常值    158832\nName: isDefault, dtype: int64\n**********\n正常值    788258\n异常值     11739\nName: ficoRangeHigh_outliers, dtype: int64\nficoRangeHigh_outliers\n异常值       778\n正常值    158832\nName: isDefault, dtype: int64\n**********\n正常值    790886\n异常值      9111\nName: openAcc_outliers, dtype: int64\nopenAcc_outliers\n异常值      2195\n正常值    157415\nName: isDefault, dtype: int64\n**********\n正常值    792468\n异常值      7529\nName: pubRec_outliers, dtype: int64\npubRec_outliers\n异常值      1701\n正常值    157909\nName: isDefault, dtype: int64\n**********\n正常值    794117\n异常值      5880\nName: pubRecBankruptcies_outliers, dtype: int64\npubRecBankruptcies_outliers\n异常值      1423\n正常值    158187\nName: isDefault, dtype: int64\n**********\n正常值    789999\n异常值      9998\nName: revolBal_outliers, dtype: int64\nrevolBal_outliers\n异常值      1359\n正常值    158251\nName: isDefault, dtype: int64\n**********\n正常值    799945\n异常值        52\nName: revolUtil_outliers, dtype: int64\nrevolUtil_outliers\n异常值        23\n正常值    159587\nName: isDefault, dtype: int64\n**********\n正常值    791660\n异常值      8337\nName: totalAcc_outliers, dtype: int64\ntotalAcc_outliers\n异常值      1668\n正常值    157942\nName: isDefault, dtype: int64\n**********\n正常值    775131\n异常值     24866\nName: title_outliers, dtype: int64\ntitle_outliers\n异常值      3900\n正常值    155710\nName: isDefault, dtype: int64\n**********\n正常值    782770\n异常值     17227\nName: n0_outliers, dtype: int64\nn0_outliers\n异常值      3485\n正常值    156125\nName: isDefault, dtype: int64\n**********\n正常值    790497\n异常值      9500\nName: n1_outliers, dtype: int64\nn1_outliers\n异常值      2491\n正常值    157119\nName: isDefault, dtype: int64\n**********\n正常值    789064\n异常值     10933\nName: n2_outliers, dtype: int64\nn2_outliers\n异常值      3205\n正常值    156405\nName: isDefault, dtype: int64\n**********\n正常值    789064\n异常值     10933\nName: n3_outliers, dtype: int64\nn3_outliers\n异常值      3205\n正常值    156405\nName: isDefault, dtype: int64\n**********\n正常值    788657\n异常值     11340\nName: n4_outliers, dtype: int64\nn4_outliers\n异常值      2476\n正常值    157134\nName: isDefault, dtype: int64\n**********\n正常值    790352\n异常值      9645\nName: n5_outliers, dtype: int64\nn5_outliers\n异常值      1858\n正常值    157752\nName: isDefault, dtype: int64\n**********\n正常值    786003\n异常值     13994\nName: n6_outliers, dtype: int64\nn6_outliers\n异常值      3182\n正常值    156428\nName: isDefault, dtype: int64\n**********\n正常值    788427\n异常值     11570\nName: n7_outliers, dtype: int64\nn7_outliers\n异常值      2746\n正常值    156864\nName: isDefault, dtype: int64\n**********\n正常值    789622\n异常值     10375\nName: n8_outliers, dtype: int64\nn8_outliers\n异常值      2131\n正常值    157479\nName: isDefault, dtype: int64\n**********\n正常值    786381\n异常值     13616\nName: n9_outliers, dtype: int64\nn9_outliers\n异常值      3953\n正常值    155657\nName: isDefault, dtype: int64\n**********\n正常值    788976\n异常值     11021\nName: n10_outliers, dtype: int64\nn10_outliers\n异常值      2639\n正常值    156971\nName: isDefault, dtype: int64\n**********\n正常值    799431\n异常值       566\nName: n11_outliers, dtype: int64\nn11_outliers\n异常值       112\n正常值    159498\nName: isDefault, dtype: int64\n**********\n正常值    797582\n异常值      2415\nName: n12_outliers, dtype: int64\nn12_outliers\n异常值       545\n正常值    159065\nName: isDefault, dtype: int64\n**********\n正常值    788904\n异常值     11093\nName: n13_outliers, dtype: int64\nn13_outliers\n异常值      2482\n正常值    157128\nName: isDefault, dtype: int64\n**********\n正常值    788881\n异常值     11116\nName: n14_outliers, dtype: int64\nn14_outliers\n异常值      3364\n正常值    156246\nName: isDefault, dtype: int64\n**********\n"
    }
   ],
   "source": [
    "# 首先，添加异常值列\n",
    "def findOutLiersBy3Segama(data, feature):\n",
    "    # 标准差\n",
    "    data_std = np.std(data[feature])\n",
    "    data_mean = np.mean(data[feature])\n",
    "    outliners_cut_off = data_std * 3\n",
    "    # 最小标准\n",
    "    lower_limit = data_mean - outliners_cut_off\n",
    "    # 最大标准\n",
    "    upper_limit = data_mean + outliners_cut_off\n",
    "    # 标注异常值\n",
    "    data[feature+'_outliers'] = data[feature].apply(lambda x: str('异常值') if x < lower_limit or x > upper_limit else '正常值')\n",
    "    return data\n",
    "\n",
    "train_data_copy = train_data.copy()\n",
    "\n",
    "exception_features = ['loanAmnt', 'term', 'interestRate', 'installment', 'employmentTitle', 'annualIncome', 'postCode', 'dti', 'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'revolBal', 'revolUtil', 'totalAcc', 'title', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14']\n",
    "\n",
    "for col in exception_features:\n",
    "    train_data_copy = findOutLiersBy3Segama(train_data_copy, col)\n",
    "    print(train_data_copy[col+'_outliers'].value_counts())\n",
    "    print(train_data_copy.groupby(col+'_outliers')['isDefault'].sum())\n",
    "    print('*'*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.19951324817468066\n"
    }
   ],
   "source": [
    "label_result = train_data['isDefault'].value_counts()\n",
    "print(label_result[1]/(label_result[0] + label_result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loanAmnt\n0\n**********\nterm\n0\n**********\ninterestRate\n0.507925448528131\n**********\ninstallment\n0.27055569524767414\n**********\nemploymentTitle\n0\n**********\nannualIncome\n0.1254355400696864\n**********\npostCode\n0.20673526660430308\n**********\ndti\n0.2987179487179487\n**********\nficoRangeLow\n0.06627481046085697\n**********\nficoRangeHigh\n0.06627481046085697\n**********\nopenAcc\n0.2409175721655142\n**********\npubRec\n0.22592641785097622\n**********\npubRecBankruptcies\n0.24200680272108843\n**********\nrevolBal\n0.13592718543708743\n**********\nrevolUtil\n0.4423076923076923\n**********\ntotalAcc\n0.20007196833393306\n**********\ntitle\n0.15684066596959703\n**********\nn0\n0.2022987171300865\n**********\nn1\n0.26221052631578945\n**********\nn2\n0.293149181377481\n**********\nn3\n0.293149181377481\n**********\nn4\n0.218342151675485\n**********\nn5\n0.19263867288750647\n**********\nn6\n0.22738316421323423\n**********\nn7\n0.23733794295592048\n**********\nn8\n0.20539759036144578\n**********\nn9\n0.2903202115158637\n**********\nn10\n0.239451955357953\n**********\nn11\n0.1978798586572438\n**********\nn12\n0.22567287784679088\n**********\nn13\n0.22374470386730372\n**********\nn14\n0.302626844188557\n**********\n"
    }
   ],
   "source": [
    "for col in exception_features:\n",
    "    d1 = train_data_copy[col+'_outliers'].value_counts()\n",
    "    d2 = train_data_copy.groupby(col+'_outliers')['isDefault'].sum()\n",
    "    print(col)\n",
    "    print(d2[0]/d1[1] if len(d1) > 1 else 0)\n",
    "    print('*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要处理的异常值\n",
    "exception_proc_features = ['installment', 'postCode', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'totalAcc', 'title', 'n0', 'n1', 'n4', 'n5', 'n6', 'n7', 'n8', 'n10', 'n11', 'n12', 'n13']\n",
    "\n",
    "for col in exception_proc_features:\n",
    "    train_data = train_data_copy[train_data_copy[col+'_outliers']=='正常值']\n",
    "    train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 数据分桶\n",
    "\n",
    "连续性数值或者多个分类的特征值可以进行分桶处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要进行分桶的特征值\n",
    "binning_features = ['loanAmnt', 'annualIncome', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'totalAcc']\n",
    "\n",
    "# 以1000为单位，进行分箱\n",
    "train_data['loanAmnt_bin'] = np.floor_divide(train_data['loanAmnt'], 1000)\n",
    "train_data['annualIncome_bin'] = np.floor_divide(train_data['annualIncome'], 1000)\n",
    "train_data['totalAcc_bin'] = np.floor_divide(train_data['totalAcc'], 1000)\n",
    "test_data['loanAmnt_bin'] = np.floor_divide(test_data['loanAmnt'], 1000)\n",
    "test_data['annualIncome_bin'] = np.floor_divide(test_data['annualIncome'], 1000)\n",
    "test_data['totalAcc_bin'] = np.floor_divide(test_data['totalAcc'], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中位数分箱\n",
    "train_data['openAcc_bin'] = pd.qcut(train_data['openAcc'], 10, labels=False, duplicates='drop')\n",
    "train_data['pubRec_bin'] = pd.qcut(train_data['pubRec'], 10, labels=False, duplicates='drop')\n",
    "train_data['pubRecBankruptcies_bin'] = pd.qcut(train_data['pubRecBankruptcies'], 10, labels=False, duplicates='drop')\n",
    "test_data['openAcc_bin'] = pd.qcut(test_data['openAcc'], 10, labels=False, duplicates='drop')\n",
    "test_data['pubRec_bin'] = pd.qcut(test_data['pubRec'], 10, labels=False, duplicates='drop')\n",
    "test_data['pubRecBankruptcies_bin'] = pd.qcut(test_data['pubRecBankruptcies'], 10, labels=False, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-283-e2c6c4af514e>, line 3)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-283-e2c6c4af514e>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    EDA中分析的，pubRec,pubRecBankruptcies和delinquency_2years做交叉应该会对模型有帮助。\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "## 2.5 特征交互\n",
    "\n",
    "EDA中分析的，pubRec,pubRecBankruptcies和delinquency_2years做交叉应该会对模型有帮助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data['pubRec_num'] = train_data['pubRec'] - train_data['pubRecBankruptcies']\n",
    "test_data['pubRec_num'] = test_data['pubRec'] - test_data['pubRecBankruptcies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_data, test_data]: \n",
    "    for item in ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9','n10','n11','n12','n13','n14']: \n",
    "        df['grade_to_mean_' + item] = df['grade'] / df.groupby([item]) ['grade'].transform('mean')\n",
    "        df['grade_to_std_' + item] = df['grade'] / df.groupby([item]) ['grade'].transform('std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 数据归一化\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['loanAmnt', 'term', 'interestRate', 'installment', 'grade', 'subGrade', 'employmentTitle', 'employmentLength', 'annualIncome', 'postCode', 'dti', 'delinquency_2years', 'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'revolBal', 'revolUtil', 'totalAcc', 'initialListStatus', 'applicationType', 'earliesCreditLine', 'title', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14', 'issueDateDt', 'homeOwnership_1', 'homeOwnership_2', 'homeOwnership_3', 'homeOwnership_4', 'homeOwnership_5', 'verificationStatus_1', 'verificationStatus_2', 'purpose_1', 'purpose_2', 'purpose_3', 'purpose_4', 'purpose_5', 'purpose_6', 'purpose_7', 'purpose_8', 'purpose_9', 'purpose_10', 'purpose_11', 'purpose_12', 'purpose_13', 'regionCode_1', 'regionCode_2', 'regionCode_3', 'regionCode_4', 'regionCode_5', 'regionCode_6', 'regionCode_7', 'regionCode_8', 'regionCode_9', 'regionCode_10', 'regionCode_11', 'regionCode_12', 'regionCode_13', 'regionCode_14', 'regionCode_15', 'regionCode_16', 'regionCode_17', 'regionCode_18', 'regionCode_19', 'regionCode_20', 'regionCode_21', 'regionCode_22', 'regionCode_23', 'regionCode_24', 'regionCode_25', 'regionCode_26', 'regionCode_27', 'regionCode_28', 'regionCode_29', 'regionCode_30', 'regionCode_31', 'regionCode_32', 'regionCode_33', 'regionCode_34', 'regionCode_35', 'regionCode_36', 'regionCode_37', 'regionCode_38', 'regionCode_39', 'regionCode_40', 'regionCode_41', 'regionCode_42', 'regionCode_43', 'regionCode_44', 'regionCode_45', 'regionCode_46', 'regionCode_47', 'regionCode_48', 'regionCode_49', 'regionCode_50', 'loanAmnt_bin', 'annualIncome_bin', 'totalAcc_bin', 'openAcc_bin', 'pubRec_bin', 'pubRecBankruptcies_bin', 'pubRec_num', 'grade_to_mean_n0', 'grade_to_std_n0', 'grade_to_mean_n1', 'grade_to_std_n1', 'grade_to_mean_n2', 'grade_to_std_n2', 'grade_to_mean_n3', 'grade_to_std_n3', 'grade_to_mean_n4', 'grade_to_std_n4', 'grade_to_mean_n5', 'grade_to_std_n5', 'grade_to_mean_n6', 'grade_to_std_n6', 'grade_to_mean_n7', 'grade_to_std_n7', 'grade_to_mean_n8', 'grade_to_std_n8', 'grade_to_mean_n9', 'grade_to_std_n9', 'grade_to_mean_n10', 'grade_to_std_n10', 'grade_to_mean_n11', 'grade_to_std_n11', 'grade_to_mean_n12', 'grade_to_std_n12', 'grade_to_mean_n13', 'grade_to_std_n13', 'grade_to_mean_n14', 'grade_to_std_n14']\n"
    }
   ],
   "source": [
    "## 2.8 简单预测\n",
    "\n",
    "features = [f for f in train_data.columns if f not in ['id', 'issueDate', 'isDefault'] and '_outliers' not in f] \n",
    "x_train = train_data[features] \n",
    "x_test = test_data[features] \n",
    "y_train = train_data['isDefault']\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb \n",
    "import lightgbm as lgb \n",
    "# from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "def cv_model(clf, train_x, train_y, test_x, clf_name): \n",
    "    folds = 5 \n",
    "    seed = 2020 \n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed) \n",
    "    train = np.zeros(train_x.shape[0]) \n",
    "    test = np.zeros(test_x.shape[0]) \n",
    "    cv_scores = [] \n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)): \n",
    "        print('************************************ {} ************************************'.format(str(i+1))) \n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index] \n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y) \n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y) \n",
    "            params = { 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'min_child_weight': 5, 'num_leaves': 2 ** 5, 'lambda_l2': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 4, 'learning_rate': 0.1, 'seed': 2020, 'nthread': 28, 'n_jobs':24, 'silent': True, 'verbose': -1, }\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200) \n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration) \n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "\n",
    "        if clf_name == \"xgb\": \n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y) \n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y) \n",
    "            params = {'booster': 'gbtree', 'objective': 'binary:logistic', 'eval_metric': 'auc', 'gamma': 1, 'min_child_weight': 1.5, 'max_depth': 5, 'lambda': 10, 'subsample': 0.7, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.7, 'eta': 0.04, 'tree_method': 'exact', 'seed': 2020, 'nthread': 36, \"silent\": True, }\n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')] \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200) \n",
    "            val_pred = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit) \n",
    "            test_pred = model.predict(test_x , ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "        if clf_name == \"cat\": \n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli', 'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            model = clf(iterations=20000, **params) \n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y), cat_features=[], use_best_model=True, verbose=500) \n",
    "            val_pred = model.predict(val_x) \n",
    "            test_pred = model.predict(test_x) \n",
    "\n",
    "        train[valid_index] = val_pred \n",
    "        test = test_pred / kf.n_splits \n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        print(cv_scores)\n",
    "\n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores) \n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores)) \n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores)) \n",
    "    return train, test\n",
    "\n",
    "def lgb_model(x_train, y_train, x_test): \n",
    "    lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\") \n",
    "    return lgb_train, lgb_test \n",
    "def xgb_model(x_train, y_train, x_test): \n",
    "    xgb_train, xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\") \n",
    "    return xgb_train, xgb_test \n",
    "def cat_model(x_train, y_train, x_test): \n",
    "    cat_train, cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\")\n",
    "    return cat_train, cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "************************************ 1 ************************************\n[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n[LightGBM] [Warning] Unknown parameter: silent\nTraining until validation scores don't improve for 200 rounds\n[200]\ttraining's auc: 0.990421\tvalid_1's auc: 0.70711\nEarly stopping, best iteration is:\n[36]\ttraining's auc: 0.838305\tvalid_1's auc: 0.726466\n[0.7264657004655278]\n************************************ 2 ************************************\n[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n[LightGBM] [Warning] Unknown parameter: silent\nTraining until validation scores don't improve for 200 rounds\n[200]\ttraining's auc: 0.989481\tvalid_1's auc: 0.680084\nEarly stopping, best iteration is:\n[33]\ttraining's auc: 0.834603\tvalid_1's auc: 0.700719\n[0.7264657004655278, 0.7007189764492754]\n************************************ 3 ************************************\n[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n[LightGBM] [Warning] Unknown parameter: silent\nTraining until validation scores don't improve for 200 rounds\n[200]\ttraining's auc: 0.99023\tvalid_1's auc: 0.686777\nEarly stopping, best iteration is:\n[74]\ttraining's auc: 0.907537\tvalid_1's auc: 0.696864\n[0.7264657004655278, 0.7007189764492754, 0.6968643762872526]\n************************************ 4 ************************************\n[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n[LightGBM] [Warning] Unknown parameter: silent\nTraining until validation scores don't improve for 200 rounds\n[200]\ttraining's auc: 0.990743\tvalid_1's auc: 0.685476\nEarly stopping, best iteration is:\n[29]\ttraining's auc: 0.823064\tvalid_1's auc: 0.704631\n[0.7264657004655278, 0.7007189764492754, 0.6968643762872526, 0.7046310783862556]\n************************************ 5 ************************************\n[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n[LightGBM] [Warning] Unknown parameter: silent\nTraining until validation scores don't improve for 200 rounds\n[200]\ttraining's auc: 0.989346\tvalid_1's auc: 0.691447\nEarly stopping, best iteration is:\n[64]\ttraining's auc: 0.893096\tvalid_1's auc: 0.711474\n[0.7264657004655278, 0.7007189764492754, 0.6968643762872526, 0.7046310783862556, 0.7114737626082658]\nlgb_scotrainre_list: [0.7264657004655278, 0.7007189764492754, 0.6968643762872526, 0.7046310783862556, 0.7114737626082658]\nlgb_score_mean: 0.7080307788393154\nlgb_score_std: 0.010405858310721845\n"
    }
   ],
   "source": [
    "lgb_train, lgb_test = lgb_model(x_train.iloc[:10000, :], y_train.iloc[:10000], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间关系，最后部分代码只来得及测试，没有详细看，抱歉！！！"
   ]
  }
 ]
}